---
title: "WIP viz prototypes for Nature"
author: "Joe A. Wasserman"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
library(knitr)
library(ragg)
library(here)
library(USAboundaries)
library(sf)
library(colorspace)
library(tidyverse)
library(ggh4x)
library(patchwork)
library(geofacet)
library(dtwclust)
library(lubridate)
library(parallel)

# set default chunk options
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  include = FALSE,
  dev = "ragg_png"
)

# set global options
options(
  scipen = 999,
  verbose = FALSE
)

# set directories
here::i_am("R/plotWIPs.Rmd")

inDir <- here::here("data", "input")
outDir <- here::here("data", "output")

theme_minimal2 <- theme_minimal() +
  theme(
    line = element_line(color = "grey40"),
    text = element_text(color = "grey10")
  )
```

```{r import data}
monthlyEstimates <- read_csv(here::here(outDir, "exMortEstimatesMonthlyINLA.csv"))
metroRaw <- read_csv(here::here(inDir, "utilities", "FIPSmetroregion4cat.csv"))
BEARegions <- read_rds(here::here(inDir, "utilities", "stateBEARegionCrosswalk.rds"))
censusRegion <- read_csv(here::here(inDir, "utilities", "FIPSmetroregion4cat.csv"))
```

# Maps of relative county excess mortality as a % (excess / expected) by COVID wave and Metro status

* Large metro = NCHS categories 1 + 2

* Small/Medium Metro = NCHS category 3

* All Metro = NCH categories 1, 2, + 3

* Non-metro = 4


```{r plot data prep, cache=TRUE}

# identify deciles to guide setting cut-points for bins for maps
# plotDataMapWave %>% filter(excDeathsRelative > 0) %>% pull(excDeathsRelative) %>% quantile(probs = seq(0, 1, .05), type = 8, digits = 4)
# .3, .6, .8, .95
breaksMap <- c(-Inf, 0, .15, .3, .45, .7, Inf)

# filter to pandemic months
plotData <- monthlyEstimates %>%
  filter(monthYear >= date("2020-03-01")) %>%
  arrange(FIPSCode, monthYear) %>% 
  left_join(BEARegions, by = c("stateStr" = "state_abb")) %>%
  mutate(
    excDeaths100k = 100000 * excDeathsMed / pop,
    excDeathsRelative = excDeathsMed / expDeathsMed,
    excDeathsRelativeBinned = cut(
      excDeathsRelative,
      breaks = breaksMap,
      ordered_result = TRUE,
      right = FALSE
    ),
    significant = coalesce(excDeathsLow > 0, FALSE)
  )

# color scale for corresponding number of bins
colorscaleGeyser21 <- colorspace::divergingx_hcl(21)
colorscaleGeyserMap <- colorscaleGeyser21[c(9, 11, 13, 15, 17, 21)]

## Metropolitan status
metro <- metroRaw %>%
  select(
    FIPSCode = fips,
    metroCode = metro
  ) %>%
  mutate(
    FIPSCode = if_else(nchar(FIPSCode) < 5, paste0("0", FIPSCode), as.character(FIPSCode)),
    metroStatus = if_else(
      metroCode %in% c(1, 2),
      "Large Metro",
      "Other"
    ),
    metroStatus2 = case_when(
      metroCode %in% c(1, 2) ~ "Large Metro",
      metroCode %in% c(3) ~ "Medium or Small Metro",
      TRUE ~ "Non Metro"
    ),
    metroStatus3 = case_when(
      metroCode %in% c(1, 2, 3) ~ "All Metro",
      TRUE ~ "Non Metro"
    )
  )

# sf objects for plotting maps
us_counties_raw <- USAboundaries::us_counties(resolution = "high")
usCounties <- names(us_counties_raw) %>%
  make.names(unique = TRUE) %>%
  purrr::set_names(us_counties_raw, .) %>%
  filter(jurisdiction_type %in% c("state", "district")) %>%
  tigris::shift_geometry(geoid_column = "statefp")

usStates <- USAboundaries::us_states(resolution = "high") %>%
  filter(jurisdiction_type %in% c("state", "district")) %>%
  tigris::shift_geometry(geoid_column = "statefp")

# map data prep
# define waves, summarize data by wave, and add sf for plotting

plotDataMapWave <- plotData %>%
  mutate(
    wave = as_factor(
      case_when(
        between(monthYear, date("2020-03-01"), date("2020-06-01")) ~ "Mar-Jun 2020",
        between(monthYear, date("2020-07-01"), date("2020-10-01")) ~ "Jul-Oct 2020",
        between(monthYear, date("2020-11-01"), date("2021-02-01")) ~ "Nov 2020 - Feb 2021",
        between(monthYear, date("2021-03-01"), date("2021-06-01")) ~ "March-Jun 2021",
        between(monthYear, date("2021-07-01"), date("2021-10-01")) ~ "Jul-Oct 2021",
        between(monthYear, date("2021-11-01"), date("2022-02-01")) ~ "Nov 2021 - Feb 2022",
        TRUE ~ NA_character_
      )
    )
  ) %>%
  filter(!is.na(wave)) %>%
  group_by(csCode, FIPSCode, stateFIPS, countyName, state, stateStr, region_bea, region_group_bea, wave) %>%
  summarize(
    across(
      c(expDeathsLow:imputedDeaths, excDeathsMed:excDeathsUp, excDeaths100k),
      sum
    ),
    .groups = "drop"
  ) %>%
  left_join(metro, by = "FIPSCode") %>%
  mutate(
    excDeathsRelative = excDeathsMed / expDeathsMed,
    excDeathsRelativeBinned = cut(
      excDeathsRelative,
      breaks = breaksMap,
      ordered_result = TRUE,
      right = FALSE
    )
  )

plotDataMapWaveGeo <- usCounties %>%
  merge(plotDataMapWave, by.x = "geoid", by.y = "FIPSCode")
```

```{r map plot}

gMap <- ggplot(
  plotDataMapWaveGeo,
  aes(
    fill = excDeathsRelativeBinned,
    geometry = geometry
  )
)

mapNationalUnfaceted <- gMap +
  geom_sf(
    color = "transparent"
  ) +
  scale_fill_manual(
    values = colorscaleGeyserMap,
    labels = c(
      "<=0%",
      "0-15%",
      "15-30%",
      "30-45%",
      "45-70%",
      ">70%"
    )
  ) +
  geom_sf(
    data = usStates,
    fill = NA,
    color = "grey60",
    size = .1
  ) +
  guides(
    fill = guide_legend(
      direction = "horizontal",
      nrow = 1,
      override.aes = list(
        color = "grey40",
        size = .1
      )
    )
  ) +
  labs(
    fill = NULL,
    title = "Relative Excess Deaths (%)"
  ) +
  theme_void() +
  theme(
    text = element_text(size = 10),
    legend.position = "bottom",
    legend.key.size = unit(0.5, "cm")
  )


mapOut <- mapNationalUnfaceted +
  facet_wrap(
    facets = vars(wave),
    ncol = 3
  )
```
```{r export map}
ragg::agg_png(
  filename = here::here("figures", "mapOut.png"),
  width = 3600,
  height = 2500,
  res = 300
)
mapOut
dev.off()
```

# Heatmaps of relative county-month excess mortality as a % (excess / expected)

* Large metro = NCHS categories 1 + 2

* Small/Medium Metro = NCHS category 3

* All Metro = NCH categories 1, 2, + 3

* Non-metro = 4

## Rows (counties) ordered by peak month + second-highest month

```{r heatmap data prep}
# identify deciles to guide setting cut-points for bins for heatmaps
# plotDataHeatmap %>% filter(excDeathsRelative > 0) %>% pull(excDeathsRelative) %>% quantile(probs = seq(0, 1, .05), type = 8, digits = 4)
# .3, .6, .8, .95
breaksHeatmap <- c(-Inf, 0, .15, .3, .5, .90, Inf)

colorscaleGeyserHeatmap <- c("white", colorscaleGeyser21[c(11, 13, 15, 17, 21)])

# specify month ranges for COVID-19 outbreak waves
waveRanges <- tibble(
  wave = c(
    "Initial",
    "Winter",
    "Delta",
    "Omicron"
  ),
  startWave = c(
    date("2020-03-01"),
    date("2020-10-01"),
    date("2021-08-01"),
    date("2021-11-01")
  ),
  endWave = c(
    date("2020-09-01"),
    date("2021-02-01"),
    date("2021-10-01"),
    date("2022-02-01")
  )
) %>%
  mutate(
    across(
      c(startWave, endWave),
      list(
        monthNum = ~ month(.x),
        yearStart = ~ floor_date(.x, unit = "years"),
        yearEnd = ~ ceiling_date(.x, unit = "years"),
        intervalSeconds = ~ int_length(
          interval(
            floor_date(.x, unit = "years"),
            ceiling_date(.x, unit = "years")
          )
        ) / 12,
        plot = ~ floor_date(.x, unit = "years") +
          hours(14) +
          seconds(
            (month(.x) - 1) *
              int_length(
                interval(
                  floor_date(.x, unit = "years"),
                  ceiling_date(.x, unit = "years")
                )
              ) / 12
          )
      )
    ),
    startWave_plot = startWave_plot - (startWave_intervalSeconds / 2.5),
    endWave_plot = endWave_plot + (endWave_intervalSeconds / 2.5),
    midWave_plot = startWave_plot + ((endWave_plot - startWave_plot) / 2),
    yjust = row_number() %% 2
  )

plotDataHeatmap <- plotData %>%
  left_join(metro, by = "FIPSCode") %>%
  group_by(FIPSCode) %>%
  mutate(
    excDeathsRelativeNoInf = na_if(excDeathsRelative, Inf),
    excDeathsRelativeNoInf = na_if(excDeathsRelativeNoInf, -Inf),
    monthRank = rank(-excDeathsRelativeNoInf, ties.method = "first", na.last = "keep"),
    monthMax1 = if_else(monthRank == 1L, monthYear, NA_Date_),
    monthMax2 = if_else(monthRank == 2L, monthYear, NA_Date_),
    monthMax3 = if_else(monthRank == 3L, monthYear, NA_Date_)
  ) %>%
  fill(
    monthMax1,
    monthMax2,
    monthMax3,
    .direction = "updown"
  ) %>%
  ungroup() %>%
  arrange(
    # maxMonth
    monthMax1,
    monthMax2,
    monthMax1
  ) %>%
  mutate(
    excDeathsRelativeBinned = cut(
      excDeathsRelative,
      breaks = breaksHeatmap,
      ordered_result = TRUE,
      right = FALSE
    ),
    FIPSPlotOrder = forcats::as_factor(FIPSCode),
    # create 12 evenly-spaced datetimes for nicer plotting
    monthNum = month(monthYear),
    yearStart = floor_date(monthYear, unit = "years"),
    yearEnd = ceiling_date(monthYear, unit = "years"),
    intervalSeconds = int_length(interval(yearStart, yearEnd)) / 12,
    monthYearPlot = yearStart + hours(14) + seconds((monthNum - 1) * intervalSeconds),
    monthTest = monthNum == month(monthYearPlot)
  )

# test that month dates modified for plotting still have the same month as the original data month
testthat::expect_true(all(plotDataHeatmap[["monthTest"]]))

FIPSTop50 <- plotDataHeatmap %>% 
  group_by(FIPSCode, metroStatus3) %>% 
  summarize(popMax = max(pop, na.rm = TRUE), .groups = "drop") %>% 
  group_by(metroStatus3) %>% 
  arrange(desc(popMax), .by_group = TRUE) %>% 
  slice(1:50) %>% 
  ungroup()

plotDataHeatmapSubset <- plotDataHeatmap %>% 
  semi_join(FIPSTop50, by = "FIPSCode") %>% 
  arrange(metroStatus3, FIPSPlotOrder) %>% 
  mutate(
    FIPSlabel = glue::glue("{countyName}, {stateStr}"),
    FIPSPlotOrder = as_factor(FIPSlabel)
    )
```
```{r heatmap plot}

# plot waves as line segment annotations
waveRangePlot <- ggplot(waveRanges) +
  geom_segment(
    aes(
      x = startWave_plot,
      xend = endWave_plot
    ),
    y = 0,
    yend = 0,
    color = "grey70"
  ) +
  geom_text(
    aes(
      x = midWave_plot,
      y = -.5 - (yjust * 1),
      label = wave
    ),
    vjust = 1.5,
    color = "grey10", 
    size = 2.5
  ) +
  coord_fixed(2628000 * .8, clip = "off") +
  theme_void()

# function to plot heatmap and "significance" side by side
plot_heatmap <- function(.x,
                         plot_title = NULL) {
  gHeatmap <- ggplot(
  .x,
  aes(
    y = FIPSPlotOrder,
    x = monthYearPlot,
    fill = excDeathsRelativeBinned,
    width = I(intervalSeconds)
  )
)
  
  heatmapUnfaceted <- gHeatmap +
  geom_tile(
    color = "transparent"
  ) +
  scale_fill_manual(
    values = colorscaleGeyserHeatmap,
    labels = c(
      "<=0%",
      "0-15%",
      "15-30%",
      "30-50%",
      "50-90%",
      ">90%"
    )
  ) +
  scale_x_datetime(
    breaks = scales::breaks_width(width = "4 months"),
    minor_breaks = scales::breaks_width(width = "1 month"),
    labels = scales::label_date_short(),
    expand = c(0, 0)
  ) +
  scale_y_discrete(
    # labels = NULL,
    limits = rev
  ) +
  labs(
    title = plot_title,
    subtitle = "Relative Excess",
    x = NULL,
    y = NULL,
    fill = "Relative Excess (%)"
  ) +
  coord_fixed(2628000 * 1.3) +
  guides(
    fill = guide_legend(
      reverse = FALSE,
      nrow = 1,
      title.position = "top",
      override.aes = list(
        color = "grey40",
        size = .1
      )
    )
  ) +
  theme_minimal2 +
  theme(
    text = element_text(size = 10),
    panel.border = element_rect(
      color = "grey40",
      size = .1,
      fill = "transparent"
    ),
    panel.grid = element_blank(),
    axis.ticks.x = element_line(
      color = "grey40",
      size = .1
    ),
    axis.ticks.length.x = unit(3, "points"),
    legend.position = "bottom",
    legend.justification = "center",
    legend.title.align = .5,
    legend.key.size = unit(0.5, "cm")
  )

significantTileUnfaceted <- gHeatmap +
  geom_tile(
    aes(
      fill = significant
    ),
    color = "transparent"
  ) +
  scale_fill_manual(
    values = c("white", "grey70"),
    labels = c(
      "<=95%",
      ">95%"
    )
  ) +
  scale_x_datetime(
    breaks = scales::breaks_width(width = "4 months"),
    minor_breaks = scales::breaks_width(width = "1 month"),
    labels = scales::label_date_short(),
    expand = c(0, 0)
  ) +
  scale_y_discrete(
    labels = NULL,
    limits = rev
  ) +
  labs(
    title = NULL,
    subtitle = "Probability of Excess > 0",
    x = NULL,
    y = NULL,
    fill = "Probability of Excess > 0"
  ) +
  coord_fixed(2628000 * 1.3) +
  guides(
    fill = guide_legend(
      reverse = FALSE,
      nrow = 2,
      title.position = "top",
      override.aes = list(
        color = "grey40",
        size = .1
      )
    )
  ) +
  theme_minimal2 +
  theme(
    text = element_text(size = 10),
    panel.border = element_rect(
      color = "grey40",
      size = .1,
      fill = "transparent"
    ),
    panel.grid = element_blank(),
    axis.ticks.x = element_line(
      color = "grey40",
      size = .1
    ),
    axis.ticks.length.x = unit(3, "points"),
    legend.position = "bottom",
    legend.justification = "center",
    legend.title.align = .5,
    legend.key.size = unit(0.5, "cm")
  )

# heatmapOut <- (heatmapUnfaceted + significantTileUnfaceted + waveRangePlot + waveRangePlot) +
heatmapOutList <- list(heatmapUnfaceted, significantTileUnfaceted)

  # heatmapOut <- (heatmapUnfaceted + significantTileUnfaceted) +
  # plot_layout(
  #   ncol = 2,
  #   guides = "collect"
  # ) + 
  # plot_annotation(title = plot_title) &
  # theme(legend.position = "bottom")
}

heatmapOut <- plotDataHeatmapSubset %>% 
  group_by(metroStatus3) %>% 
  group_map(plot_heatmap) %>% 
  map(wrap_plots) %>% 
  map(~ .x[[1]] + plot_layout(tag_level = "new") + .x[[2]]) %>% 
  wrap_plots(
    nrow = 1,
    guides = "collect"
  ) +
  plot_annotation(tag_levels = c("a", "1")) &
  theme(
    legend.position = "bottom",
    legend.justification = "center",
    legend.title.align = .5
  )

```
```{r export heatmap, eval=FALSE}
ragg::agg_png(
  filename = here::here("figures", "heatmap.png"),
  width = 3600,
  height = 2100,
  res = 300
)
heatmapOut
dev.off()
```

# Clustering counties' timeseries of excess deaths

Using dynamic time warping, 17 clusters seems to be the best solution initially.
As seen in the results, some clusters are more interpretable than others.

```{r cluster timeseries data prep, cache=TRUE, eval=FALSE}
# restructure data and set 0 as floor, because negative "excess" deaths are not of interest here
dataForClust <- plotDataHeatmap %>%
  select(FIPSCode, monthYear, excDeathsRelative) %>%
  mutate(excDeathsRelative = pmax(0, excDeathsRelative)) %>% 
  pivot_wider(
    names_from = monthYear,
    values_from = excDeathsRelative,
    names_sort = TRUE
  ) %>% 
  arrange(FIPSCode)

dataForClustMatrix <- dataForClust %>%
  select(-FIPSCode) %>%
  as.matrix()

rownames(dataForClustMatrix) <- as.character(dataForClust[["FIPSCode"]])

dataForClustLists <- tslist(dataForClustMatrix)
```
```{r cluster timeseries, cache=TRUE, eval=FALSE}
# set options for partitional clustering using dynamic time warping
partitionalConfigs <- compare_clusterings_configs(
    types = "partitional", 
    # k = c(5L:12L, 14:40L),
    # k = 16L:21L,
    k = 16L:64L,
    controls = list(
        partitional = partitional_control(
            iter.max = 1000L,
            nrep = 1L
        )
    ),
    preprocs = pdc_configs(
        "preproc",
        zscore = list(center = c(FALSE))
    ),
    distances = pdc_configs(
        "distance",
        dtw_basic = list(
          window.size = 0L:2L,
          norm = c("L1", "L2")
        )
    ),
    centroids = pdc_configs(
        "centroid",
        partitional = list(
            dba = list(
              window.size = 0L:2L,
              norm = c("L1", "L2")
            )
        )
    ),
    no.expand = c("window.size", "norm")
)

# list evaluators for picking "best" result
partitionalEvaluators <- cvi_evaluators(type = c("Sil", "D", "COP", "DB", "DBstar", "CH"))

# start parallelization
workers <- parallel::makeCluster(detectCores())
# load dtwclust in each core, and make them use 1 thread per worker
invisible(parallel::clusterEvalQ(workers, {
    library(dtwclust)
    RcppParallel::setThreadOptions(1L)
}))
# register workers
require(doParallel)
registerDoParallel(workers)

clusterResult <- dtwclust::compare_clusterings(
  series = dataForClustLists,
  types = c("partitional"),
  seed = 20220914L,
  trace = FALSE,
  configs = partitionalConfigs,
  score.clus = partitionalEvaluators[["score"]],
  pick.clus = partitionalEvaluators[["pick"]],
  return.objects = TRUE
)

parallel::stopCluster(workers)
```
## Preview initial cluster results

An error in this section indicates that no cluster validity indices agreed.

```{r preview cluster results, include=TRUE, results='asis', cache=TRUE, eval=FALSE}
# qwraps2::lazyload_cache_dir(here::here("R", "plotWIPS_cache", "html"))

# print(clusterResult[["results"]][["partitional"]])

# function to extract and plot just the centroid of clusters for easier viz
plot_centroids <- function(partitionalObject) {
  
  objectCentroids <- partitionalObject@centroids
  
  g <- objectCentroids %>% 
    map(enframe, name = "seq") %>% 
    map(ggplot, aes(x = seq, y = value)) %>% 
    imap(~ .x + 
           geom_line() + 
           labs(title = .y, x = NULL, y = NULL) +
           theme_minimal() +
           theme(axis.text = element_blank())
         ) %>% 
    patchwork::wrap_plots()
}

# if one solution receives the majority of votes, print its info
try(print(clusterResult[["pick"]]))

try(plot(clusterResult[["pick"]][["object"]]))

try(print(plot_centroids(clusterResult[["pick"]][["object"]])))

# assuming there is no pick, identify and display top results
resultSummaryBest <- clusterResult[["results"]][["partitional"]] %>% 
  mutate(
    across(
      c(Sil, D, CH, COP, DB, DBstar),
      list(
        percentile = percent_rank,
        best = ~ .x == max(.x)
      )
    )
  ) %>% 
  rowwise() %>% 
  mutate(
    avg_percentile = mean(c_across(ends_with("_percentile"))),
    total_bests = sum(c_across(ends_with("_best")))
  ) %>% 
  ungroup() %>% 
  arrange(-total_bests, -avg_percentile) %>% 
  filter(total_bests > 0)

resultSummaryBest %>% 
  kable(digits = 3) %>% 
  kableExtra::kable_styling(bootstrap_options = "condensed") %>% 
  print()

# plot just centroids of the top results that converged
centroidPlots <- clusterResult$objects.partitional[names(clusterResult$objects.partitional) %in% resultSummaryBest[["config_id"]]] %>%
  keep(~ .@converged) %>%
  map2(
    .,
    names(.),
    ~ plot_centroids(.x) + 
      patchwork::plot_annotation(title = .y)
    )

walk(centroidPlots, print)

# extract partitions and summary info from selected solution
partitionSelect <- clusterResult$objects.partitional$config1_2
```

```{r cluster timeseries data prep 02, cache=TRUE, eval=FALSE}
# restructure data and set 0 as floor, because negative "excess" deaths are not of interest here
dataForClust02 <- plotDataHeatmap %>%
  filter(model == "monthly") %>% 
  select(FIPSCode, monthYear, excDeathsRelative) %>%
  mutate(excDeathsRelative = pmax(0, excDeathsRelative)) %>% 
  pivot_wider(
    names_from = monthYear,
    values_from = excDeathsRelative,
    names_sort = TRUE
  ) %>% 
  arrange(FIPSCode)

dataForClustMatrix02 <- dataForClust02 %>%
  select(-FIPSCode) %>%
  as.matrix()

rownames(dataForClustMatrix02) <- as.character(dataForClust02[["FIPSCode"]])

dataForClustLists02 <- tslist(dataForClustMatrix02)
```
```{r cluster timeseries 02, cache=TRUE, eval=FALSE}
# set options for partitional clustering using dynamic time warping
partitionalConfigs02 <- compare_clusterings_configs(
    types = "partitional", 
    k = 6L:32L,
    controls = list(
        partitional = partitional_control(
            iter.max = 2000L,
            nrep = 1L
        )
    ),
    preprocs = pdc_configs(
        "preproc",
        none = list(),
        zscore = list(center = c(FALSE))
    ),
    distances = pdc_configs(
        "distance",
        dtw_basic = list(
          window.size = 0L:2L,
          norm = c("L1", "L2")
        )
    ),
    centroids = pdc_configs(
        "centroid",
        partitional = list(
            dba = list(
              window.size = 0L:2L,
              norm = c("L1", "L2")
            )
        )
    ),
    no.expand = c("window.size", "norm")
)

# start parallelization
workers <- parallel::makeCluster(detectCores())
# load dtwclust in each core, and make them use 1 thread per worker
invisible(parallel::clusterEvalQ(workers, {
    library(dtwclust)
    RcppParallel::setThreadOptions(1L)
}))
# register workers
require(doParallel)
registerDoParallel(workers)

clusterResult02 <- dtwclust::compare_clusterings(
  series = dataForClustLists02,
  types = c("partitional"),
  seed = 20220914L,
  trace = TRUE,
  configs = partitionalConfigs02,
  score.clus = partitionalEvaluators[["score"]],
  pick.clus = partitionalEvaluators[["pick"]],
  return.objects = TRUE
)

parallel::stopCluster(workers)
```

```{r cluster timeseries 02 narrow subset, eval=FALSE}
# set options for partitional clustering using dynamic time warping
partitionalConfigs03 <- compare_clusterings_configs(
    types = "partitional", 
    k = 6L:11L,
    controls = list(
        partitional = partitional_control(
            iter.max = 2000L,
            nrep = 1L
        )
    ),
    preprocs = pdc_configs(
        "preproc",
        none = list(),
        zscore = list(center = c(FALSE))
    ),
    distances = pdc_configs(
        "distance",
        dtw_basic = list(
          window.size = 0L:2L,
          norm = c("L1", "L2")
        )
    ),
    centroids = pdc_configs(
        "centroid",
        partitional = list(
            dba = list(
              window.size = 0L:2L,
              norm = c("L1", "L2")
            )
        )
    ),
    no.expand = c("window.size", "norm")
)

# start parallelization
workers <- parallel::makeCluster(detectCores())
# load dtwclust in each core, and make them use 1 thread per worker
invisible(parallel::clusterEvalQ(workers, {
    library(dtwclust)
    RcppParallel::setThreadOptions(1L)
}))
# register workers
require(doParallel)
registerDoParallel(workers)

clusterResult03 <- dtwclust::compare_clusterings(
  series = dataForClustLists02,
  types = c("partitional"),
  seed = 20220914L,
  trace = TRUE,
  configs = partitionalConfigs03,
  score.clus = partitionalEvaluators[["score"]],
  pick.clus = partitionalEvaluators[["pick"]],
  return.objects = TRUE
)

parallel::stopCluster(workers)
```

## Preview second cluster results

In the first iteration, results were affected by counties with substantial data suppression, in which case a yearly model was used in place of monthly.
The yearly model induced additional year-to-year systematic differences, such that this methodological artifact influenced the creation of several clusters.
A second attempt at clustering was performed after dropping these counties.



```{r preview cluster results 02, include=TRUE, results='asis', cache=TRUE, eval=FALSE}
# qwraps2::lazyload_cache_dir(here::here("R", "plotWIPS_cache", "html"))

# print(clusterResult02[["results"]][["partitional"]])

# if one solution receives the majority of votes, print its info
try(print(clusterResult03[["pick"]]))

try(plot(clusterResult03[["pick"]][["object"]]))

try(print(plot_centroids(clusterResult03[["pick"]][["object"]])))

# assuming there is no pick, identify and display top results
resultSummaryBest03 <- clusterResult03[["results"]][["partitional"]] %>% 
  mutate(
    across(
      c(Sil, D, CH, COP, DB, DBstar),
      list(
        percentile = percent_rank,
        best = ~ .x == max(.x)
      )
    )
  ) %>% 
  rowwise() %>% 
  mutate(
    avg_percentile = mean(c_across(ends_with("_percentile"))),
    total_bests = sum(c_across(ends_with("_best")))
  ) %>% 
  ungroup() %>% 
  arrange(-avg_percentile, -total_bests) %>% 
  filter(total_bests > 0 | avg_percentile > .7)

resultSummaryBest03 %>% 
  kable(digits = 3) %>% 
  kableExtra::kable_styling(bootstrap_options = "condensed") %>% 
  print()

# plot just centroids of the top results that converged
centroidPlots03 <- clusterResult03$objects.partitional[names(clusterResult03$objects.partitional) %in% resultSummaryBest03[["config_id"]]] %>%
  keep(~ .@converged) %>%
  map2(
    .,
    names(.),
    ~ plot_centroids(.x) + 
      patchwork::plot_annotation(title = .y)
    )

walk(centroidPlots03, print)

# extract partitions and summary info from selected solution
partitionSelect03 <- clusterResult03[["pick"]][["object"]]
```

## Final selected clustering solution

(Ignore "NA" in mode columns, they're an artifact of calculating the mode and weren't worth taking the time to get rid of.)

```{r heatmap cluster plot data prep, include=TRUE, eval=FALSE}
plotDataHeatmapCluster02 <- dataForClust02 %>% 
  add_column(cluster = partitionSelect02@cluster) %>% 
  select(FIPSCode, cluster) %>% 
  right_join(plotDataHeatmap, by = "FIPSCode")
```
```{r selected result details, include=TRUE, results='asis', eval=FALSE}
partitionSelect02@clusinfo %>% 
  mutate(partition = row_number()) %>% 
    kable(digits = 3) %>% 
  kableExtra::kable_styling(bootstrap_options = "condensed") %>% 
  print()

plot_centroids(partitionSelect02) %>% 
  print()

countyClusterDescriptive02 <- plotDataHeatmapCluster02 %>% 
  group_by(cluster) %>% 
  add_count(metroCat, name = "metroCat_n") %>% 
  add_count(BEARegion, name = "BEARegion_n") %>% 
  mutate(
    across(
      c(metroCat_n, BEARegion_n),
      list(max = max)
    ),
    metroCat_mode = if_else(
      metroCat_n == metroCat_n_max, 
      metroCat, 
      NA_character_
    ),
    BEARegion_mode = if_else(
      BEARegion_n == BEARegion_n_max, 
      BEARegion, 
      NA_character_
    )
  ) %>% 
  summarize(
    metroCat_mode = toString(unique(metroCat_mode)),
    BEARegion_mode = toString(unique(BEARegion_mode)),
    across(
      c(pop, monthMax1, excDeathsRelative, significant),
      list(mean = mean, sd = sd)
    ),
    .groups = "drop"
  )

countyClusterDescriptive02 %>% 
  knitr::kable(digits = 2) %>% 
  kableExtra::kable_styling(bootstrap_options = "condensed") %>% 
  print()
```

## Plot counties by DTW cluster from selected solution
```{r cluster heatmap plots, include=TRUE, output='asis', eval=FALSE}
heatmapPlotCluster02 <- distinct(plotDataHeatmapCluster02, cluster) %>% 
  drop_na() %>% 
  deframe() %>% 
  map(
    ~ filter(plotDataHeatmapCluster02, cluster == .x) %>% 
      plot_heatmap(plot_title = paste("Cluster", .x))
  )

walk(heatmapPlotCluster02, print)
```
```{r export cluster heatmaps, eval=FALSE}
ragg::agg_png(
  filename = here::here("figures", "heatmapClusterV02_%02d.png"),
  width = 2700,
  height = 3600,
  res = 300,
  scaling = 1.2
)
heatmapPlotCluster02
dev.off()
```

# Barplots!

```{r barplot data prep}
# identify deciles to guide setting cut-points for bins for bar graphs
# plotDataBar %>% filter(excDeathsRelative > 0) %>% pull(excDeathsRelative) %>% quantile(probs = seq(0, 1, .05), type = 8, digits = 4)
# .3, .6, .8, .95
breaksBar <- c(-Inf, 0, .1, .2, .35, .55, Inf)


plotDataBar <- plotDataHeatmap %>%
  group_by(
    stateFIPS,
    state,
    stateStr,
    region_bea,
    region_group_bea,
    metroStatus,
    monthYear,
    monthYearPlot,
    intervalSeconds
  ) %>%
  summarize(
    across(
      c(expDeathsLow:imputedDeaths, excDeathsMed:excDeathsUp, excDeaths100k),
      sum
    ),
    .groups = "drop"
  ) %>%
  mutate(
    excDeathsRelative = excDeathsMed / expDeathsMed,
    excDeathsRelativeBinned = cut(
      excDeathsRelative,
      breaks = breaksBar,
      ordered_result = TRUE,
      right = FALSE
    ),
    excDeathsRelative = pmax(excDeathsRelative, 0),
    significant = coalesce(excDeathsLow > 0, FALSE)
  )
```

```{r bar plots}
gBarplot <- plotDataBar %>%
  ggplot(
    aes(
      x = monthYearPlot,
      y = excDeathsRelative * 100,
      fill = excDeathsRelativeBinned,
      width = I(intervalSeconds)
    )
  )

barplotOut <- gBarplot +
  geom_col(
    color = "transparent"
  ) +
  geom_segment(
    data = filter(plotDataBar, significant),
    aes(
      x = monthYearPlot - (intervalSeconds / 2),
      xend = monthYearPlot + (intervalSeconds / 2)
    ),
    y = 0,
    yend = 0,
    color = "grey30",
    size = .3
  ) +
  scale_y_continuous(
    # breaks = scales::breaks_extended(n = 3)
    breaks = seq.int(0L, 250L, 50L)
  ) +
  scale_x_datetime(
    breaks = scales::breaks_width(width = "4 months"),
    labels = scales::label_date_short(),
    expand = c(0, 0)
  ) +
  scale_fill_manual(
    values = colorscaleGeyserHeatmap,
    labels = c(
      "<=0%",
      "0-10%",
      "10-20%",
      "20-35%",
      "35-55%",
      ">55%"
    )
  ) +
  scale_linetype_manual(
    values = c("dotted", "solid"),
    labels = c(">95%")
  ) +
  ggh4x::facet_nested(
    rows = vars(region_group_bea, stateStr),
    cols = vars(metroStatus),
    scales = "free_y",
    space = "free_y",
    remove_labels = TRUE,
    nest_line = element_line(),
    strip = strip_nested(
      size = "variable",
      text_y = list(
        element_text(),
        element_text(angle = 0)
      ),
      by_layer_y = TRUE
    )
  ) +
  guides(
    fill = guide_legend(
      order = 1,
      nrow = 1,
      title.position = "top",
      title.hjust = 1,
      override.aes = list(
        color = "grey60",
        size = .1
      )
    ),
    linetype = guide_legend(
      order = 2,
      nrow = 2,
      title.position = "top",
      title.hjust = 0,
      override.aes = list(
        size = .4
      )
    )
  ) +
  labs(
    y = "Relative Excess (%)",
    x = NULL,
    fill = "Relative Excess (%)",
    linetype = "Probability of Excess > 0"
  ) +
  theme_minimal2 +
  theme(
    text = element_text(size = 8),
    axis.ticks.x = element_line(
      color = "grey40",
      size = .1
    ),
    axis.ticks.length.x = unit(2, "points"),
    panel.grid.major.x = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major.y = element_line(size = .25),
    # panel.spacing.y = unit(2, "points"),
    ggh4x.facet.nestline = element_line(
      size = .3
    ),
    legend.position = "bottom",
    legend.key.size = unit(0.5, "cm")
  )
```

```{r export barplot}
ragg::agg_png(
  filename = here::here("figures", "barplot.png"),
  width = 2160,
  height = 3600,
  res = 300
)
barplotOut
dev.off()
```

# Geofacet

```{r geofacet data prep}

plotDataGeofacet <- mutate(
  plotDataHeatmap, 
  metroCat = "State Total")  %>% 
  bind_rows(plotDataHeatmap) %>% 
  group_by(
    stateFIPS,
    state,
    stateStr,
    monthYear,
    metroCat
  ) %>% 
  summarize(
    across(
      c(expDeathsLow:imputedDeaths, excDeathsMed:excDeathsUp, excDeaths100k),
      sum,
      na.rm = TRUE
    ),
    .groups = "drop"
  ) %>% 
  mutate(
    excDeathsRelative = excDeathsMed / expDeathsMed
  )

```

```{r geofacet plots, eval=FALSE}
geofacetPalette <- colorspace::qualitative_hcl(palette = "Dark 3", n = 5)[2:5]

gGeofacet <- ggplot(
  plotDataGeofacet,
  aes(
    x = monthYear,
    y = excDeathsRelative * 100,
    linetype = metroCat,
    color = metroCat
  )
)

gGeofacet +
  geom_line() +
  scale_linetype_manual(
    values = c(5:1)
  ) +
  scale_color_manual(
    values = c(geofacetPalette, "grey20")
  ) +
  scale_x_date(
    # expand = c(0, 0),
    breaks = scales::breaks_width(width = "4 months"),
    labels = scales::label_date_short()
  ) +
  scale_y_continuous(
    # expand = c(0, 0),
    oob = scales::oob_keep
  ) +
  coord_cartesian(
    ylim = c(NA, 150),
    expand = FALSE,
    clip = "off"
  ) +
  facet_geo(facets = ~ state) +
  labs(
    y = "Relative Excess (%)",
    x = NULL,
    color = "County Category",
    linetype = "County Category"
  ) +
  theme_minimal2 +
  theme(
    text = element_text(size = 10),
    panel.border = element_rect(
      color = "grey40",
      size = .1,
      fill = "transparent"
    ),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(),
    axis.ticks.x = element_line(
      color = "grey40",
      size = .1
    ),
    axis.ticks.length.x = unit(3, "points"),
  )
```

```{r geofacet spaghetti plots}

us_state_grid_custom <- data.frame(
  row = c(1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7),
  col = c(12, 11, 11, 12, 4, 10, 8, 5, 3, 6, 2, 1, 11, 12, 4, 10, 9, 6, 7, 5, 3, 8, 2, 1, 2, 10, 9, 4, 5, 7, 3, 8, 1, 6, 11, 7, 9, 3, 6, 4, 5, 8, 11, 6, 7, 8, 5, 4, 2, 9, 1),
  code = c("ME", "NH", "VT", "MA", "ND", "NY", "MI", "MN", "MT", "WI", "ID", "WA", "CT", "RI", "SD", "NJ", "PA", "IL", "IN", "IA", "NE", "OH", "WY", "OR", "NV", "MD", "VA", "CO", "KS", "KY", "UT", "WV", "CA", "MO", "DE", "TN", "NC", "AZ", "AR", "NM", "OK", "SC", "DC", "MS", "AL", "GA", "LA", "TX", "AK", "FL", "HI"),
  name = c("Maine", "New Hampshire", "Vermont", "Massachusetts", "North Dakota", "New York", "Michigan", "Minnesota", "Montana", "Wisconsin", "Idaho", "Washington", "Connecticut", "Rhode Island", "South Dakota", "New Jersey", "Pennsylvania", "Illinois", "Indiana", "Iowa", "Nebraska", "Ohio", "Wyoming", "Oregon", "Nevada", "Maryland", "Virginia", "Colorado", "Kansas", "Kentucky", "Utah", "West Virginia", "California", "Missouri", "Delaware", "Tennessee", "North Carolina", "Arizona", "Arkansas", "New Mexico", "Oklahoma", "South Carolina", "District of Columbia", "Mississippi", "Alabama", "Georgia", "Louisiana", "Texas", "Alaska", "Florida", "Hawaii"),
  stringsAsFactors = FALSE
)

plotDataGeofacet <- mutate(
  plotDataHeatmap, 
  group = "State Total"
  )  %>% 
  group_by(
    stateFIPS,
    state,
    stateStr,
    monthYear,
    group
  ) %>% 
  summarize(
    across(
      c(expDeathsLow:imputedDeaths, excDeathsMed:excDeathsUp, excDeaths100k),
      sum,
      na.rm = TRUE
    ),
    .groups = "drop"
  ) %>% 
  mutate(
    excDeathsRelative = excDeathsMed / expDeathsMed
  ) %>% 
  bind_rows(plotDataHeatmap) %>% 
  filter(pop > 30000 | is.na(pop))

gGeofacet <- ggplot(
  plotDataGeofacet,
  aes(
    x = monthYear,
    y = excDeathsRelative * 100,
    # linetype = metroStatus,
    group = countyName,
    alpha = group
  )
)

geofacetOut <- gGeofacet +
  geom_line(
    color = "grey10"
  ) +
  scale_alpha_discrete(
    range = c(1, 1),
    na.value = .075
  ) +
  scale_x_date(
    # expand = c(0, 0),
    breaks = scales::breaks_width(width = "4 months"),
    labels = scales::label_date_short()
  ) +
  scale_y_continuous(
    # expand = c(0, 0),
    oob = scales::oob_keep
  ) +
  coord_cartesian(
    ylim = c(NA, 150),
    expand = FALSE,
    clip = "off"
  ) +
  facet_geo(
    facets = ~ state,
    grid = us_state_grid_custom
  ) +
  labs(
    y = "Relative Excess (%)",
    x = NULL,
    color = "County Category",
    linetype = "County Category"
  ) +
  guides(
    color = "none",
    alpha = "none"
  ) +
  theme_minimal2 +
  theme(
    text = element_text(size = 10),
    panel.border = element_rect(
      color = "grey40",
      size = .1,
      fill = "transparent"
    ),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(),
    axis.ticks.x = element_line(
      color = "grey40",
      size = .1
    ),
    axis.ticks.length.x = unit(3, "points")
  )
```
```{r export geofacet}
ragg::agg_png(
  filename = here::here("figures", "geofacet.png"),
  width = 3600,
  height = 2500,
  res = 300
)
geofacetOut
dev.off()
```


```{r geofacet heatmap, eval=FALSE}

FIPSTop25State <- plotDataHeatmap %>% 
  group_by(FIPSCode, state) %>% 
  summarize(popMax = max(pop, na.rm = TRUE), .groups = "drop") %>% 
  group_by(state) %>% 
  arrange(desc(popMax), .by_group = TRUE) %>% 
  slice(1:25) %>% 
  ungroup()

plotDataHeatmapSubsetGeofacet <- plotDataHeatmap %>% 
  semi_join(FIPSTop25State, by = "FIPSCode") %>% 
  arrange(state, FIPSPlotOrder) %>% 
  mutate(
    FIPSlabel = glue::glue("{countyName}, {stateStr}"),
    FIPSPlotOrder = as_factor(FIPSlabel)
    )

  gHeatmap <- ggplot(
  plotDataHeatmapSubsetGeofacet,
  aes(
    y = FIPSPlotOrder,
    x = monthYearPlot,
    fill = excDeathsRelativeBinned,
    width = I(intervalSeconds)
  )
)
  
  (heatmapGeofacet <- gHeatmap +
  geom_tile(
    color = "transparent"
  ) +
  scale_fill_manual(
    values = colorscaleGeyserHeatmap,
    labels = c(
      "<=0%",
      "0-15%",
      "15-30%",
      "30-50%",
      "50-90%",
      ">90%"
    )
  ) +
  scale_x_datetime(
    breaks = scales::breaks_width(width = "4 months"),
    minor_breaks = scales::breaks_width(width = "1 month"),
    labels = scales::label_date_short(),
    expand = c(0, 0)
  ) +
  scale_y_discrete(
    labels = NULL,
    limits = rev,
    expand = c(0,0)
  ) +
  labs(
    title = NULL,
    subtitle = NULL,
    x = NULL,
    y = NULL,
    fill = "Relative Excess (%)"
  ) +
  # coord_fixed(2628000 * 1) +
  facet_geo(
    facets = ~ state,
    scales = "free_y",
    shrink = TRUE
  ) +
  guides(
    fill = guide_legend(
      reverse = FALSE,
      nrow = 1,
      title.position = "top",
      override.aes = list(
        color = "grey40",
        size = .1
      )
    )
  ) +
  theme_minimal2 +
  theme(
    text = element_text(size = 10),
    panel.border = element_rect(
      color = "grey40",
      size = .1,
      fill = "transparent"
    ),
    panel.grid = element_blank(),
    axis.ticks.x = element_line(
      color = "grey40",
      size = .1
    ),
    axis.ticks.length.x = unit(3, "points"),
    legend.position = "bottom",
    legend.justification = "center",
    legend.title.align = .5,
    legend.key.size = unit(0.5, "cm")
  ))

```
